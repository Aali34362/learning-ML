ML.NET gives you the ability to add machine learning to .NET applications, 
in either online or offline scenarios. With this capability, 
you can make automatic predictions using the data available to your application. 
Machine learning applications make use of patterns in the data to make predictions rather than needing to be explicitly programmed.

Central to ML.NET is a machine learning model. 
The model specifies the steps needed to transform your input data into a prediction. 
With ML.NET, you can train a custom model by specifying an algorithm, or you can import pre-trained TensorFlow and ONNX models.

Once you have a model, you can add it to your application to make the predictions.

ML.NET runs on Windows, Linux, and macOS using .NET, or on Windows 
using .NET Framework. 64 bit is supported on all platforms. 32 bit is supported on Windows, 
except for TensorFlow, LightGBM, and ONNX-related functionality.

Prediction type & Example:
Classification/Categorization : Automatically divide customer feedback into positive and negative categories.
Regression/Predict continuous values : Predict the price of houses based on size and location.
Anomaly Detection : Detect fraudulent banking transactions.
Recommendations : Suggest products that online shoppers may want to buy, based on their previous purchases.
Time series/sequential data : Forecast the weather or product sales.
Image classification : Categorize pathologies in medical images.
Text classification : Categorize documents based on their content.
Sentence similarity :Measure how similar two sentences are.

Code workflow

The following diagram represents the application code structure, 
as well as the iterative process of model development:

    Collect and load training data into an IDataView object
    Specify a pipeline of operations to extract features and apply a machine learning algorithm
    Train a model by calling Fit() on the pipeline
    Evaluate the model and iterate to improve
    Save the model into binary format, for use in an application
    Load the model back into an ITransformer object
    Make predictions by calling CreatePredictionEngine.Predict()

Machine learning model:
An ML.NET model is an object that contains transformations to perform on your input data to arrive at the predicted output.

Basic:
The most basic model is two-dimensional linear regression, where one continuous quantity is proportional to another, as in the house price example above.

More complex
A more complex model classifies financial transactions into categories using the transaction text description.
Each transaction description is broken down into a set of features by removing redundant words and characters, 
and counting word and character combinations. 
The feature set is used to train a linear model based on the set of categories in the training data.
The more similar a new description is to the ones in the training set, the more likely it will be assigned to the same category.

In most cases, the data that you have available isn't suitable to be used directly to train a machine learning model. 
The raw data needs to be prepared, or pre-processed, before it can be used to find the parameters of your model.
Your data may need to be converted from string values to a numerical representation. 
You might have redundant information in your input data. 
You may need to reduce or expand the dimensions of your input data. 
Your data might need to be normalized or scaled.

The ML.NET tutorials teach you about different data processing pipelines for text, image, numerical, 
and time-series data used for specific machine learning tasks.


Model evaluation

Once you have trained your model, how do you know how well it will make future predictions? With ML.NET, 
you can evaluate your model against some new test data.
Each type of machine learning task has metrics used to evaluate the accuracy and precision of the model against the test data set.
The evaluation metrics tell you that the error is low-ish, and that correlation between the predicted output and the test output is high. 
That was easy! In real examples, it takes more tuning to achieve good model metrics.

ML.NET architecture:
This section describes the architectural patterns of ML.NET. 
If you're an experienced .NET developer, some of these patterns will be familiar to you, and some will be less familiar.
An ML.NET application starts with an MLContext object. This singleton object contains catalogs.
A catalog is a factory for data loading and saving, transforms, trainers, and model operation components.
Each catalog object has methods to create the different types of components.

Task ->	Catalog
Data loading and saving ->	DataOperationsCatalog
Data preparation ->	TransformsCatalog
Binary classification ->	BinaryClassificationCatalog
Multiclass classification ->	MulticlassClassificationCatalog
Anomaly detection ->	AnomalyDetectionCatalog
Clustering ->	ClusteringCatalog
Forecasting ->	ForecastingCatalog
Ranking ->	RankingCatalog
Regression v	RegressionCatalog
Recommendation ->	RecommendationCatalog
Time series ->	TimeSeriesCatalog
Model usage ->	ModelOperationsCatalog


Build the pipeline:
Inside each catalog is a set of extension methods that you can use to create a training pipeline.
Concatenate and Sdca are both methods in the catalog. 
They each create an IEstimator object that's appended to the pipeline.
At this point, the objects have been created, but no execution has happened.

Train the model:
Once the objects in the pipeline have been created, data can be used to train the model.
Calling Fit() uses the input training data to estimate the parameters of the model. 
This is known as training the model. Remember, the linear regression model shown earlier had two model parameters: bias and weight. 
After the Fit() call, the values of the parameters are known.
The resulting model object implements the ITransformer interface. 
That is, the model transforms input data into predictions.

Use the model:
You can transform input data into predictions in bulk, or one input at a time. 
The house price example did both: in bulk for the purpose of evaluating the model, and one at a time to make a new prediction. 
var size = new HouseData() { Size = 2.5F };
var predEngine = mlContext.CreatePredictionEngine<HouseData, Prediction>(model);
var price = predEngine.Predict(size);
The CreatePredictionEngine() method takes an input class and an output class. 
The field names or code attributes determine the names of the data columns used during model training and prediction. 

Data models and schema:
At the core of an ML.NET machine learning pipeline are DataView objects.
Each transformation in the pipeline has an input schema 
(data names, types, and sizes that the transform expects to see on its input); 
and an output schema (data names, types, and sizes that the transform produces after the transformation).
If the output schema from one transform in the pipeline doesn't match the input schema of the next transform, ML.NET will throw an exception.
A data view object has columns and rows. 
Each column has a name and a type and a length. 
For example, the input columns in the house price example are Size and Price. 
They are both type and they are scalar quantities rather than vector ones. 



-------------------------------------------------------------------------------------------------------------------------
GPT

MLContext : 
The MLContext class in ML.NET is the main entry point for interacting with all machine learning operations, 
including data loading, transformation, model training, evaluation, and deployment. 
It acts as a factory for creating various components that are essential for machine learning workflows in .NET applications. 
Each instance of MLContext can manage its own machine learning environment and resources.

Creating an MLContext Object:
An MLContext object is usually created at the start of a machine learning workflow. 
It holds configurations and instances for all the operations, and it manages memory and resources during model creation and training.

Key Properties and Methods of MLContext:
The MLContext object has several key properties and methods that provide access to machine learning operations. 
These are grouped into several areas:

a) Data Loading and Processing:
i. Data.LoadFromTextFile<T>(string path, ...)
    Loads data from a text file (e.g., CSV) into an IDataView, which is the primary data structure in ML.NET.    
    IDataView dataView = mlContext.Data.LoadFromTextFile<ModelInput>("data.csv", hasHeader: true, separatorChar: ',');
    
ii. Data.LoadFromEnumerable<T>(IEnumerable<T> data)
    Loads data from an in-memory collection like a list or array.
    List<ModelInput> dataList = GetData();
    IDataView dataView = mlContext.Data.LoadFromEnumerable(dataList);

iii. Data.Split(...)
    Splits the dataset into training and test datasets.
    var splitData = mlContext.Data.TrainTestSplit(dataView, testFraction: 0.2);

iv. Data.ShuffleRows(...)
    Randomly shuffles the rows of data, useful for cross-validation.
    IDataView shuffledData = mlContext.Data.ShuffleRows(dataView);

b) Data Transformation:
Transformations are used to modify, clean, or prepare data before feeding it to a machine learning algorithm.
i. Transforms
    The Transforms property provides various transformations, including normalization, text featurization, categorical encoding, and more. 
    Common transformations include:
    Text Featurization:
    var textPipeline = mlContext.Transforms.Text.FeaturizeText("Features", "TextColumn");
    One-Hot Encoding (for categorical data):
    var encodingPipeline = mlContext.Transforms.Categorical.OneHotEncoding("CategoryEncoded", "Category");
    Normalization (scaling numeric data):
    var normalizationPipeline = mlContext.Transforms.NormalizeMinMax("Features");
    Concatenation (combining multiple columns into a single feature vector):
    var concatPipeline = mlContext.Transforms.Concatenate("Features", new[] { "Column1", "Column2" });

c) Model Training and Algorithms
BinaryClassification, MulticlassClassification, Regression, Clustering, and Ranking
MLContext provides access to a variety of machine learning algorithms through different properties based on the type of task you’re solving.
    Binary Classification:
    var trainer = mlContext.BinaryClassification.Trainers.SdcaLogisticRegression();
    Multiclass Classification:
    var trainer = mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy();
    Regression:
    var trainer = mlContext.Regression.Trainers.FastTree();
    Clustering:
    var trainer = mlContext.Clustering.Trainers.KMeans();
    Ranking:
    var trainer = mlContext.Ranking.Trainers.FastTree();
These methods provide access to specific machine learning algorithms, and you can append them to data processing pipelines for training.

d) Model Evaluation
Once a model is trained, it's essential to evaluate its performance using evaluation metrics.
i. BinaryClassification.Evaluate(...)
    Evaluates a binary classification model using metrics like accuracy, precision, recall, F1 score, and AUC.
    var metrics = mlContext.BinaryClassification.Evaluate(predictions);
    Console.WriteLine($"Accuracy: {metrics.Accuracy}");
ii. MulticlassClassification.Evaluate(...)
    Evaluates a multiclass classification model with metrics like micro-accuracy, macro-accuracy, and log-loss.
    var metrics = mlContext.MulticlassClassification.Evaluate(predictions);
    Console.WriteLine($"Macro Accuracy: {metrics.MacroAccuracy}");
iii. Regression.Evaluate(...)
    Evaluates a regression model using metrics like R-squared, mean absolute error, and root mean square error.
    var metrics = mlContext.Regression.Evaluate(predictions);
    Console.WriteLine($"R-Squared: {metrics.RSquared}");
iv. Clustering.Evaluate(...)
    Evaluates a clustering model with metrics like normalized mutual information and average distance.
    var metrics = mlContext.Clustering.Evaluate(predictions);
    Console.WriteLine($"NMI: {metrics.NormalizedMutualInformation}");

e) Saving and Loading Models
i. Model.Save(...)
    Saves a trained model to disk so it can be reused later.
    mlContext.Model.Save(trainedModel, dataView.Schema, "model.zip");
ii. Model.Load(...)
    Loads a previously saved model from disk for making predictions.
    var loadedModel = mlContext.Model.Load("model.zip", out var schema);

f) AutoML
The Auto property gives access to ML.NET’s AutoML (automated machine learning) capabilities. 
This allows you to build models without manually selecting algorithms and parameters.
var experimentResult = mlContext.Auto().CreateRegressionExperiment(60).Execute(trainData, labelColumnName: "Label");

g) Time Series and Forecasting
ML.NET supports time series forecasting using Singular Spectrum Analysis (SSA). This is useful for tasks such as sales forecasting, inventory management, and more.
i. Forecasting.ForecastBySsa(...)
    A method for forecasting future values based on historical data.
    var forecastingPipeline = mlContext.Forecasting.ForecastBySsa(...);

h) Logging and Debugging
i. Log
The MLContext also has options for logging, which can help in debugging and monitoring the model training process.
MLContext mlContext = new MLContext();
mlContext.Log += (sender, e) => Console.WriteLine(e.Message);
i) Random Seed
i. MLContext(seed)
You can provide a seed value for random operations to ensure reproducibility of experiments. Setting a seed makes the training process deterministic.
MLContext mlContext = new MLContext(seed: 0);

Best Practices with MLContext
    Reuse MLContext: It is recommended to reuse a single instance of MLContext throughout your application.
    Creating multiple instances can lead to memory leaks or excessive resource usage.
    Thread Safety: The MLContext object is thread-safe, so you can share it across multiple threads in your application.


--------------
IDataView:
IDataView is the primary data structure used in ML.NET for data manipulation and processing. 
It is an efficient, lazy-loading, columnar format designed to handle large datasets that might not fit in memory all at once. 
It abstracts data in a way that allows for efficient transformations and machine learning operations, 
without eagerly loading all data into memory. 
Here's an in-depth explanation of IDataView, its role, what LoadFromEnumerable does, 
and other supported formats and methods to work with data in ML.NET:
1. What is IDataView?
IDataView is similar to a table in a relational database. It provides a schema (like column names and types) and the actual data. 
It is designed to handle datasets that are too large to fit in memory by operating in a streaming fashion.
Schema: Defines the column names and their types (e.g., TextColumn as string and Label as bool). 
Data: The actual data rows, accessed lazily (i.e., not loaded into memory all at once). 
IDataView is immutable and read-only, meaning you can't change its contents once created, 
but you can apply transformations to produce new IDataView instances.

2. What Does Data.LoadFromEnumerable Do? 
The LoadFromEnumerable method converts an in-memory collection of objects (like a List<T>) into an IDataView object. 
This is useful when you already have data loaded in memory 
(e.g., from an external source like a JSON file, a database query, or manually created data).

This code performs the following steps: 
Infers the Schema: 
Reads the properties from the HouseData class and creates columns in the IDataView corresponding to those properties. 
Lazily Loads the Data: 
The data from the houseData list is not loaded into memory immediately. 
Instead, IDataView wraps it in a streaming manner so that the data is processed as needed (e.g., during training or transformations).

3. Other Ways to Create and Load Data into IDataView
ML.NET supports various methods for loading data into IDataView beyond LoadFromEnumerable. 
Here are the most commonly used ones:
a) Loading from a CSV or Text File
The LoadFromTextFile method is used to load data from a CSV or text file into an IDataView. 
This method requires specifying a schema or using attributes like [LoadColumn] in a class to map columns.

IDataView dataView = mlContext.Data.LoadFromTextFile<ModelInput>(
    path: "data.csv",
    hasHeader: true,
    separatorChar: ','
);

This method performs the following operations:
    Infers the Schema: Reads the first line (if hasHeader is true) and creates columns based on the structure of the file.
    Lazy Loading: Similar to LoadFromEnumerable, LoadFromTextFile loads rows on-demand, making it memory efficient for large files.

b) Loading from a Database
ML.NET supports loading data directly from a relational database like SQL Server. 
The DatabaseLoader is used to read data from tables or views in a SQL database and convert it into an IDataView.

// Define a database loader.
var loader = mlContext.Data.CreateDatabaseLoader<ModelInput>();

// Define a connection string and SQL command.
string connectionString = "Server=.;Database=SampleDB;Integrated Security=true";
string sqlCommand = "SELECT * FROM HouseData";

// Load data from database.
IDataView dataView = loader.Load(new DatabaseSource(connectionString, sqlCommand));

This allows you to work with large datasets directly in the database without having to load the entire table into memory.

c) Loading from In-Memory Collections
If you have in-memory data, you can use LoadFromEnumerable as shown above.

List<ModelInput> inputData = new List<ModelInput> { ... };
IDataView dataView = mlContext.Data.LoadFromEnumerable(inputData);

d) Loading from Binary Format
If you have a large dataset that you want to save and reload multiple times (e.g., during development),
you can serialize it into a binary format using the Save and Load methods:

// Save IDataView to a binary file
using (var fileStream = new FileStream("data.idv", FileMode.Create))
{
    mlContext.Data.SaveAsBinary(trainingData, fileStream);
}

// Load IDataView from a binary file
IDataView loadedDataView;
using (var stream = new FileStream("data.idv", FileMode.Open))
{
    loadedDataView = mlContext.Data.LoadFromBinary(stream);
}

This is useful for speeding up data loading when working with large datasets.

e) Manual Creation using DataViewBuilder
You can create an IDataView manually using the DataViewBuilder class. 
This approach is useful when you want to create a small test dataset directly in code.

var builder = new DataViewBuilder(mlContext);
builder.AddColumn("Size", NumberType.Float, new float[] { 1.1f, 2.5f, 3.3f });
builder.AddColumn("Price", NumberType.Float, new float[] { 100000, 200000, 300000 });
IDataView dataView = builder.Build();

This approach provides a flexible way to create IDataView for small data samples or tests.

4. Other Formats to Work with Data
In addition to the above methods, ML.NET provides other options for working with data, such as:
TextLoader: 
For more fine-grained control over text file loading, especially when the schema is complex or requires special handling of missing values or delimiters.
JSON Files: 
While there's no direct method to load JSON into IDataView, you can first read the JSON file into an in-memory collection and then use LoadFromEnumerable.
Azure Storage: 
You can read data directly from Azure Blob Storage using the appropriate data connectors.

5. Modifications Made by LoadFromEnumerable
LoadFromEnumerable creates an IDataView object, which provides the following modifications:
Schema Inference: 
LoadFromEnumerable infers the schema based on the types and properties of the input class (e.g., ModelInput).
Lazy Loading: 
Data is not fully loaded into memory. Instead, IDataView references the original collection, allowing for large datasets to be processed efficiently.
Type Conversion: 
If the properties in the class have types that are not directly supported by IDataView (e.g., nullable types), 
LoadFromEnumerable will handle conversions where possible.